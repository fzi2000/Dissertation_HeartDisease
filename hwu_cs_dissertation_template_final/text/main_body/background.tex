\section{Background}
\label{sec:back}

This chapter explores the primary concepts and offers an overview of existing literature in this domain. Following this, it presents a critical analysis of the studies discussed, aiming to establish a solid foundation for the research.

\subsection{Background}
\label{sec:back_A}
\subsubsection{Cardiovascular diseases} \leavevmode
\\Cardiovascular disease is a broad term used to describe a variety of disorders affecting the heart and blood arteries. There are four different types of \gls{cvd} such as coronary heart disease, stroke, peripheral arterial disease and aortic disease \citep{yassine2014automatic}. It induces many illnesses, disabilities, and deaths\citep{hospitalization2001}. Disease diagnosis is a significant part of healthcare. A heart attack occurs when a coronary artery becomes suddenly blocked, typically due to a blood clot. Symptoms of a heart attack include chest pain, shortness of breath, and fatigue.

\vspace{0.5em} % Adds space between subsections

\subsubsection{Machine Learning} \leavevmode
\\Machine learning is a subset within the broader field of \gls{ai}. It focuses on developing systems capable of learning from experience and making predictions accordingly \citep{shah2020heart}.

\noindent Machine Learning models are broadly divided into two types: supervised and unsupervised models. Supervised learning involves training a model with labelled data to make predictions or classifications. It is suitable for classification scenarios where a set of inputs can result in an output. Popular supervised machine learning algorithms include Logistic Regression, \gls{svm}, and Random Forests \citep{lee2023shap}.
For example, Random Forest has shown high
accuracy in \gls{cvd} predictions due to its ability to handle large feature spaces and reduce
overfitting through ensemble learning.\citep{breiman2001random}. \\
In contrast, unsupervised learning models aim to identify hidden patterns or relationships within the data without any predefined guidance \citep{careervira2023}. Patients can be clustered into different groups based on similarities in their health data, potentially revealing new subgroups of risk factors or disease phenotypes. K-Means clustering and \gls{pca} are common unsupervised algorithms that have been employed.\vspace{0.5em}

\subsubsection{Deep Learning} \leavevmode
\\\gls{dl} is a subset of machine learning that uses multilayered \gls{nn} to imitate the decision-making power of the human brain. The main difference between deep learning and machine learning is the framework of the neural network architecture. Traditional \gls{ml} methods rely on simple neural networks with one or two computational layers. \\
\noindent Deep learning models train with three or more layers, typically hundreds or thousands of layers  \citep{ibm2024deeplearning}. They can identify patterns in patient data which might not be captured by traditional machine learning models. A conventional deep learning model consists of three main types of layers. They are the input layer- the layer which receives the input from the data, the hidden layers – intermediate layers that process the data to learn and the output layer which generates the prediction. The information learnt is propagated throughout the network using the hidden layers. Commonly used deep learning frameworks include \gls{ann}, fully connected neural networks and \gls{cnn}. Deep learning models are increasingly being used due to their multiple advantages such as increasing scalability with large datasets and the ability to learn and process complex data. \vspace{0.5em}

\subsubsection{Risk Factors associated with cardiovascular diseases and Risk Stratification} \leavevmode
\\Several factors contribute to an individual's susceptibility to cardiovascular disease. Main influences include age, gender, cholesterol levels, blood sugar levels, and heart rate, among others \citep{garcia2023heart}. The identification of heart disease is particularly challenging due to a multitude of risk factors, such as diabetes, hypertension, elevated cholesterol levels, abnormal pulse rates, and various other elements that can significantly impact cardiovascular health. This complexity highlights the necessity for comprehensive evaluations and tailored interventions to effectively address these risks \citep{mohan2019effective}. \\
\noindent Risk stratification is a process that categorises input into different risk levels based on the likelihood that it experiences a certain outcome. It plays a pivotal role in healthcare by identifying patients with high-risk scores and providing immediate treatment. For instance, in cardiovascular disease prediction, patients can be stratified into risk categories such as low, medium and high. Hence, risk stratification aids in providing patients with personalized treatment based on their risk profiles. \vspace{0.4em}

\subsubsection{Explainable AI (XAI)} \leavevmode
\\Explainable artificial intelligence is a set of techniques used to help human users understand and trust the results predicted by machine learning models \citep{ibm2023explainable}. It advocates for the development of ML approaches that maintain strong performance while being more interpretable, enabling humans to interpret and trust the next generation of \gls{ai} systems more effectively \citep{arrieta2020explainable}. Its goal is to promote greater transparency in the realm of artificial intelligence. Artificial intelligence is becoming more accessible. When AI suggests a decision, the decision-makers must understand the underlying cause. However, when making significant life-changing decisions, such as a medical diagnosis, it is crucial to understand the reasoning behind such a critical decision. This highlights the importance of explainability in AI predictions \citep{adadi2018peeking}. \\
Common explainable AI methods used are \gls{shap} and \gls{lime}. These two insightful methods help to explain the behaviour of the trained ML model. \gls{lime} provides localized insights for the user whereas \gls{shap} gives a broader overview which is critical for complex models. \gls{shap} values are derived from game theory and help quantify how each feature contributes to a prediction. A high \gls{shap} value indicates that the feature has a major impact on the prediction. The formula for \gls{shap} value for a feature in prediction is illustrated below.\citep{molnar2024interpretable}

\[
\phi_i= \sum_{S \subseteq N \setminus \{i\}} \frac{|S|! (|N| - |S| - 1)!}{|N|!} \left( f(S \cup \{i\}) - f(S) \right) 
\] 
where:  \vspace{0.5em}

\(\phi_i\) is the Shapley value for feature \(i\), representing its contribution to the model prediction. \(S\) is any subset of features excluding \(i\), \(N\) is the total set of features in the model, and \(f(S)\) represents the model prediction using only the features in subset \(S\). \(f(S \cup \{i\})\) computes the model prediction using the features in \(S\) along with feature \(i\). \(|S|\) is the number of features in subset \(S\), and \(|N|!\) is the factorial of the number of total features, which represents all possible combinations.


\subsection{Relevant Work }
\label{sec:back_B}
This section explores the research landscape of \gls{cvd} prediction using \gls{ml} techniques, drawing insights from existing research papers on supervised learning models, ensemble techniques, deep learning, and explainable AI. \\

\noindent\textbf{Prediction of Coronary Heart Disease using Supervised Machine Learning Algorithms (2019) }
In their 2019 study, Divya Krishnani et al. performed a comparative analysis of the performance of various \gls{ml} algorithms in predicting coronary heart disease risk. Their main research objective was to improve the accuracy of predictions by using algorithms such as Random Forests, Decision Trees, and K-Nearest Neighbours \citep{krishnani2019prediction}. The study shows the performance of a model using Random Forests in handling tabular and noisy data. The usage of the Framingham Heart Study dataset played a vital role in training the model with 4,240 records and 16 different features. The authors optimized the model by applying random oversampling to address null values and class imbalance. The use of random oversampling helps to mitigate the issue of class imbalance in datasets. It ensured both classes had equal representation. The study found that the Random Forest algorithm outperformed the other algorithms examined, with a remarkable accuracy of 96.8\%. It outperforms Decisions Trees and K-Nearest Neighbour algorithms. Additionally, Random Forests showed resilience to data inconsistency. \\
However, this study concentrated solely on three specific algorithms, ignoring a broader review of various techniques that could enhance cardiovascular disease predictions. It missed a broader exploration of alternative methods such as built-in explainability features. Evaluating the model with more metrics and using a larger dataset could enhance its application in clinical settings.  Future work could include developing a hybrid model that combines the interpretability of simple models with the effective predictive power of complex models. Adding methods like \gls{shap} or \gls{lime} could strengthen interpretability and provide a clearer explanation of which features influence predictions. 
\vspace{0.5 cm}

\noindent \textbf{Improving the accuracy of prediction of heart disease risk based on ensemble classification techniques (2019) }
The authors investigated the effectiveness of ensemble classification techniques for predicting heart disease risk. Their research aimed to improve the predictive accuracy of various weak classifiers by employing methods such as bagging, boosting, and stacking on a heart disease dataset \cite{latha2019improving}. They noted that \gls{svm}s resulted in the highest accuracy (92.1\%), followed by neural networks (91\%). Decision trees were slightly lower at around 89.6\%. They found that ensemble methods led to a significant increase in prediction accuracy, achieving up to a 7\% improvement for weaker classifiers. This study highlights the potential of ensemble techniques to enhance predictive models in the medical field. Ensemble methods are effective in addressing the limitations of single weak classifiers, such as high variance or bias. Even though ensemble techniques improve accuracy, they could increase computational complexity, posing challenges for real-time deployment.  It primarily emphasizes ensemble approaches without a thorough comparison to other classification methods, potentially overlooking alternative strategies that could yield similarly high accuracy. Bagging is a method that reduces model variance by training models. Boosting builds sequential models that rectify errors during each iteration. For example, the accuracy of the Naïve Bayes classifier increased by 0.99\% with boosting. But, it may amplify noise in the data which could result in overfitting. \citep{chen2016xgboost}. \\ 
The authors evaluated multiple classifiers including Naïve Bayes, Random Forest, C4.5, Multilayer Perceptron, and PART, both individually and in ensemble models. Random Forest showed a good performance due to its ability to handle non-linear data  \citep{breiman2001random}.  However, it lacks interpretability which is essential in healthcare models\citep{rudin2019stop}. The authors did not investigate advanced feature selection methods like genetic algorithms which could refine feature sets. \cite{guyon2002feature}. They mainly focused on accuracy as a performance metric. Even though accuracy is an important metric, it may not fully reflect the model’s reliability in situations where false positives and false negatives are used. Implementing precision and recall would provide further insights into the model’s effectiveness in prediction while minimizing unnecessary false positives \citep{davis2006relationship}. Future research could focus on balancing accuracy with interpretability by combining interpretable models like decision trees with ensemble methods.
\vspace{0.5 cm}

\noindent \textbf{Deep Learning for Cardiovascular Risk Stratification (2020)}
In 2020, Schlesinger and Stultz investigated the potential of deep learning in the realm of cardiovascular risk categorization \citep{schlesinger2020deep}. Schlesinger and Stultz argue that a predictive model must offer insights and be interpretable by doctors. This is a significant reasoning as understanding model interpretation is crucial. Several methods like Shapley values and Gradient-weighted Class Activation Mapping (Grad-CAM) are used to improve the model’s interpretability. This approach adds meaning in clinical usage. They identify the most influential features in the model’s predictions. They focused their study on the need for better accuracy in risk assessment tools in the healthcare sector. The main purpose was to analyse the effectiveness of the deep learning models when compared to standard ones, especially in identifying high-risk patients who might benefit from quick intervention. The authors mentioned several deep-learning techniques for medical image analysis and structured electronic health record data. The study presents numerous benefits of \gls{dl} models. They can analyse raw data while minimising the need for preprocessing and feature engineering. Despite these benefits, the need for large and high-quality datasets, and the possibility of model overfitting poses some challenges. The study does not address how the model might predict different demographics and socio-economic backgrounds depicting the importance of choosing diverse datasets for model training. They also suggest identifying failure modes which are the situations where the model may perform poorly. \\ Although they are preferred for their interpretability, conventional risk models like logistic regression and Cox proportional hazards models, fail to capture complex, non-linear relationships between patient characteristics and results. To ensure the model's fit for real-world scenarios, they also highlighted how important it is for the predictions to be transparent and comprehensible. The study also concentrates on \gls{cnn} for image-based applications. Cardiovascular disease prediction may rely on other data sources such as structured electronic health records (EHR). The paper finishes by advocating that deep learning models must be integrated which would enhance the predictive accuracy in clinical diagnosis. Future work could include developing a hybrid model that integrates both traditional and deep learning techniques. This integration would bridge the gap between accuracy and interpretability, ensuring models are clinically useful and trustworthy. 
\vspace{0.5 cm}

\noindent
\textbf{Heart Disease Prediction using Hybrid Machine Learning Model (2021)}
This research paper proposed a novel hybrid \gls{ml} model to enhance heart disease prediction \citep{kavitha2021heart}. The authors implemented a hybrid model as a novel technique for better-optimized results by merging Decision Tree and Random Forest algorithms. They aimed to combine the strengths of both algorithms to enhance prediction accuracy. In the hybrid approach, the probabilities generated from one model (Random Forest) are used as input for the other model (Decision Tree), thereby improving robustness and reducing the likelihood of overfitting. By integrating the probabilistic outputs of both machine learning techniques, it provides a comprehensive approach to disease prediction. \\The study sought to leverage the Cleveland heart disease dataset and split the data into 70\% training and 30\% testing subsets. It used data mining techniques, including regression and classification, to effectively analyse patient health data. The proposed work used a TkInter Python-designed application with sklearn libraries, pandas and matplotlib. Evaluation metrics such as mean square error (MSE), mean absolute error (MAE), R-Squared parameter, root mean square error (RMSE) and accuracy were implemented to evaluate the effectiveness of the proposed model. The authors evaluated model performance based on accuracy. Experimental results demonstrated that the hybrid model achieved 88\% accuracy, outperforming the Decision Tree (79\%) and Random Forest (81\%) when used individually.  The research highlights the potential of machine learning techniques in improving early detection and intervention for heart diseases. Additionally, the paper mentions optimization techniques like Genetic Algorithms and \gls{pso} for feature selection. However, it does not implement these techniques, leaving potential improvements unexplored. Future research could focus on expanding the dataset and applying deep learning techniques for higher predictive accuracy. Researchers could also explore multi-class classification approaches and deep learning techniques to examine the severity of heart disease. 
\vspace{0.5 cm}

\noindent
\textbf{\gls{xai} Framework for Cardiovascular Disease Prediction Using Classification Techniques (2022)}
In their 2022 research, Guleria et al. presented an explainable artificial intelligence framework aimed at enhancing cardiovascular disease prediction using advanced classification methods \citep{guleria2022comprehensive}. They investigated the benefits of ensemble classifiers on the \gls{xai} framework \citep{baghdadi2023advanced}. Their main objective was to improve the interpretability and reliability of machine learning models, by employing ensemble classifiers such as \gls{svm},\gls{knn}, and AdaBoost. By combining results from multiple classifiers, ensemble techniques such as bagging and boosting were used to increase prediction robustness by improving the overall predictive stability. These methods enable to create a balanced predictive framework by addressing the limitations of individual models.\\ This study correlates with \cite{bizimana2024automated}, which showed the role of \gls{shap} and LIME in enhancing model interpretability. The study uses correlation analysis, neighbourhood component analysis, SHAP values, and LIME to identify key features in a predictive model, focusing on age and sex as critical predictors. \gls{svm} is highlighted for its capability to handle multidimensional data. The dataset used in this study was sourced from the UCI \gls{ml} repository comprising 303 instances and 14 attributes. The study illustrated the need for explainable models in clinical settings, where understanding the reasoning behind predictions is crucial for effective decision-making. The effectiveness of the XAI-based cardiovascular disease prediction models was evaluated using a variety of evaluation criteria, such as \gls{auc}, accuracy, sensitivity, and F1-score, to assess model performance. \\
According to their findings, the ensemble classifiers performed better in distinguishing between patients who were at risk of heart disease from those who were not. They attained an accuracy of 89\%. Outcomes showed that the XAI-driven ensemble classifiers outperformed traditional classification models in terms of efficiency, with the \gls{svm} algorithm obtaining the maximum accuracy of 82.5\%. \\
This research underscores how crucial it is to incorporate XAI concepts into healthcare applications to improve diagnostic procedures and foster greater clinician trust in predictive models. The significance of explainable artificial intelligence was emphasised by the researchers, who cited Gunning D. (2019) as saying that “Explainable AI will develop a set of machine learning algorithms which will allow individual users to comprehend, adequately trust, and manage the next era of artificially intelligent companions”. The reliance on a small-sized dataset limits the model's generalizability. To improve the robustness of heart disease classification algorithms, the study recommends that future research concentrate on real-time data collection and further statistical analysis using a variety of datasets, including the UK Biobank dataset and the Statlog heart disease dataset.
\vspace{0.5 cm}

\noindent
\textbf{Advanced machine learning techniques for cardiovascular disease early detection and diagnosis (2023) }  
In their 2023 study, Baghdadi et al. contributed to the growing body of evidence by emphasising the importance of machine learning in the early detection and diagnosis of cardiovascular diseases \citep{baghdadi2023advanced}. The study aimed to leverage health data from hospital databases to create effective machine learning algorithms that enhance the predictive accuracy of \gls{cvd} risk assessments. The researchers introduced a Gradient Booster model, which achieved an F1-score of 92.3\% and an overall accuracy of 90.94\%. This highlights the critical need for early diagnosis and treatment to improve patient outcomes and reduce healthcare costs. It also tried to determine the feature that contributes the most to the prediction. \\
The dataset used in this study was synthesized from the UCI ML Repository, combining five heart datasets to create the largest heart disease dataset available for research, featuring 11 common attributes.  The authors used Google Colab as the framework for implementing machine learning models. Their approach comprised a thorough preprocessing of the data, feature selection using Shapley values along with rigorous model evaluation based on various performance metrics. To ensure reliable estimates of the model's generalization capability, Baghdadi et al. implemented K-Fold cross-validation. The top 20 predictors of heart disease were shown in order of relevance using a summary plot of Shapley values. The authors use CatBoost with feature engineering, which handles both structured and unstructured data effectively.\\
The findings of this study revealed that machine learning techniques not only facilitate early diagnosis but also significantly lessen the financial strain on healthcare systems. Since the research relied on secondary data, there were some missing values present. Additionally, Gradient Boosting methods require high computational power, which can limit the model’s applicability in resource-constrained settings. This research underlines the potential of machine learning in enhancing cardiovascular care through evidence-based decision-making. Hence, it shows the importance of integrating advanced analytics in clinical practice. The authors suggest that future research should concentrate on using datasets that cover a wider range of risk variables, both modifiable and non-modifiable. \\
\vspace{0.5 em}

\noindent
\textbf{Automated heart disease prediction using improved explainable learning-based technique (2024)}
In their 2024 study, Bizimana et al. proposed an \gls{ielbt} focusing on improving heart disease prediction \citep{bizimana2024automated}. The authors refined the dataset to select only the most predictive features using techniques like Random Forest, Recursive Feature Elimination, and Support Vector Machine. The use of the \gls{shap} method enhances the interpretability of the model. However, the use of SHAP doesn’t guarantee computational demands especially when scaling the model to larger datasets. To build a reliable predictive model, the authors integrated different feature selection strategies, data normalisation strategies, and machine learning algorithms. They obtained an excellent accuracy of 96.00\% using \gls{svm}, greatly surpassing previous models in the literature, utilising the Alizadeh Sani heart disease dataset. 
A standout feature of this study is the use of explainable AI methods, specifically \gls{shap} and \gls{lime}. It emphasises model interpretability. However, the study's dependence on a single dataset raises questions on how broadly applicable the findings might be. Testing the model on diverse datasets would strengthen the model's application in clinical settings. Further studies may build on this work by evaluating the \gls{ielbt} on various datasets to determine its effectiveness in various clinical settings. It could explore the use of deep learning models, such as Convolutional Neural Networks and Long Short-Term Memory networks. These models can handle large healthcare datasets.
% \vspace{-\baselineskip}
\vspace{0.2 cm}
\subsection{Critical Analysis of Relevant Works}

\begin{longtable}{p{2.3cm}p{1cm}p{3cm}p{5.2cm}p{4.5cm}}
\hline
\textbf{Author(s)} & \textbf{Year} & \textbf{Article Name} & \textbf{Description} & \textbf{Limitations} \\
\hline
Divya Krishnani, Anjali Kumari, Akash Dewangan, Aditya Singh, Nenavath Srinivas Naik & 2019 & Prediction of Coronary Heart Disease using Supervised Machine Learning Algorithms & This study aims to predict the risk of \gls{chd} by using various machine learning algorithms, including Random Forest, Decision Trees, and K-Nearest Neighbours. In order to increase model accuracy, the authors use the Framingham Heart Study dataset and concentrate on thorough preprocessing approaches; using Random Forest, they were able to achieve an accuracy of 96.8\%. & The comparative analysis lacks qualitative explanations for why some models perform better and is mainly quantitative. It misses opportunities to delve deeper into the behaviour of the models. Despite its high accuracy, Random Forest lacks interpretability, which restricts its clinical use.\\ \hline

C. Beulah Christalin Latha, S. Carolin Jeeva & 2019 & Improving the accuracy of prediction of heart disease risk based on ensemble classification techniques & This study explores the use of ensemble classification techniques to improve the accuracy of heart disease risk prediction. The authors conducted experiments using various ensemble methods, including bagging, boosting, and stacking, on a heart disease dataset. They reported an accuracy increase of up to 7\% for weak classifiers through ensemble techniques, demonstrating the effectiveness of these methods in enhancing predictive performance. & The study focuses primarily on the use of ensemble methods without a comprehensive comparison to other individual classification techniques that may also provide high accuracy. The study focused on accuracy and overlooked other critical metrics like precision and recall which are crucial in healthcare applications.\\
\hline
Daphne E. Schlesinger, Collin M. Stultz & 2020 & Deep Learning for Cardiovascular Risk Stratification & Using health data from hospital databases, this study suggests innovative machine learning methods for the early diagnosis of cardiovascular illnesses. The authors provide a Catboost model with an accuracy of 90.94\% and an F1-score of 92.3\%, emphasising feature selection. & While the study demonstrates remarkable accuracy, it primarily focuses on one machine learning model without conducting a comparative analysis with several other cutting-edge methods. Even though deep learning models like CatBoost are beneficial, it could be difficult to comprehend them in clinical settings. \\
\hline
Dr. M. Kavitha, G. Gnaneswar, R. Dinesh, Y. Rohith Sai, R. Sai Suraj & 2021 & Heart Disease Prediction using Hybrid Machine Learning Model & This research proposes a hybrid machine learning model combining Random Forest and Decision Trees. The hybrid technique achieves an accuracy of 88.7\%. The authors highlight the advantages of using a hybrid model to improve prediction accuracy and use the Cleveland Heart Disease dataset. & Although the hybrid model shows improved accuracy, the study lacks a comprehensive evaluation of the distinct contributions made by each of the hybrid model's algorithms.  The dataset is limited to Cleveland which may limit the model's generalizability to broader populations. \\
\hline
Pratiyush Guleria, Parvathaneni Naga Srinivasu, Shakeel Ahmed, Naif Almusallam, Fawaz Khaled Alarfaj & 2022 & XAI Framework for Cardiovascular Disease Prediction Using Classification Techniques & This review discusses that in comparison to conventional techniques, deep learning has the potential to increase prediction accuracy when creating risk stratification models for cardiovascular illnesses. It stresses the importance of comprehending failure mechanisms and evaluating models in clinical situations. & The study offers an excellent overview, but it does not offer new insights. While ensemble methods enhance accuracy, they increase computational complexity which could affect deployment in resource-limited situations.  \\
\hline
Nadiah A. Baghdadi, Sally Mohammed Farghaly Abdelaliem, Amer Malki, Ibrahim Gad, Ashraf Ewis, Elsayed Atlam & 2023 & Advanced machine learning techniques for cardiovascular disease early detection and diagnosis & This research focuses on using cutting-edge machine learning methods, such as Catboost, to identify and diagnose cardiovascular illnesses. The authors emphasize the role of feature selection in improving model performance, obtaining an F1-score of 92.3\%. & While the paper highlights the importance of feature selection, it does not go into detail about the particular features which constitute the model, impacting its utility in real-world clinical settings. \\
\hline
Pierre Claver Bizimana, Zuping Zhang, Alphonse Houssou Hounye, Muhammad Asim, Mohamed Hammad, Ahmed A. Abd El-Latif & 2024 & Automated heart disease prediction using improved explainable learning-based technique & \gls{ielbt} for predicting cardiac disease is presented. The authors combine feature selection techniques, data normalisation, and ML algorithms. Using a support vector machine, they tested their model on the Alizadeh Sani heart disease dataset and obtained an accuracy of 96.00\%.  The study highlights the model's interpretability and offers insights using SHAP and LIME methods. & While the \gls{ielbt} achieved great accuracy, the study's concentration on a single dataset may restrict the generalisability of results to larger populations.  \\
\hline
\caption{Critical Analysis of Cardiovascular Disease Prediction Studies}
\end{longtable}
\label{tab:heart_disease_studies}


\subsection{Conclusion}
The reviewed literature provides a substantial contribution to the field of machine learning in cardiovascular disease prediction. It examines a variety of models using different methodologies and datasets but there are notable limitations. \\Many of these studies focus on providing binary outcomes without categorizing individuals into distinct risk levels, which is a significant drawback. While significant strides have been achieved in \gls{cvd} prediction, there exists a tradeoff between accuracy and interpretability. Existing studies, including those by Krishnani et al. and Schlesinger and Stultz, demonstrate that even highly accurate models are limited by their lack of explainability. While Bizimana et al. mainly focused on refining a single dataset with SHAP, Baghdadi et al. leveraged multiple datasets, making their results more generalizable. The studies emphasize feature selection and ensemble methods, showing that they enhance prediction accuracy. They highlight the need for a balance between accuracy and explainability. Understanding the risk level is crucial, especially for high-risk patients, as it allows medical professionals to prioritize treatments effectively rather than relying solely on basic predictions.\vspace{0.5cm } \\ As a result, this project aims to address these limitations by developing a model to predict heart disease and stratify patients into risk levels. It will evaluate the performance of various machine-learning algorithms.
